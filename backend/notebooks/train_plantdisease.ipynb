{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = r'C:\\Users\\PC\\Desktop\\mlearning\\backend\\dataset\\train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    validation_split=0.2  # Use 20% of the data for validation\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 52247 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),  # Resize to match model's expected input\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # For multi-class classification\n",
    "    subset='training'  # Set as training data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13060 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # For multi-class classification\n",
    "    subset='validation'  # Set as validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(len(train_generator.class_indices), activation='softmax')  # Output size matches number of classes\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1632/1632 [==============================] - 1767s 1s/step - loss: 0.2664 - accuracy: 0.8879 - val_loss: 0.2389 - val_accuracy: 0.8955\n",
      "Epoch 2/10\n",
      "1632/1632 [==============================] - 9195s 6s/step - loss: 0.2334 - accuracy: 0.8993 - val_loss: 0.3156 - val_accuracy: 0.8930\n",
      "Epoch 3/10\n",
      "1632/1632 [==============================] - 3602s 2s/step - loss: 0.2141 - accuracy: 0.9035 - val_loss: 0.8161 - val_accuracy: 0.8026\n",
      "Epoch 4/10\n",
      "1632/1632 [==============================] - 1837s 1s/step - loss: 0.2081 - accuracy: 0.9068 - val_loss: 0.7668 - val_accuracy: 0.8411\n",
      "Epoch 5/10\n",
      "1632/1632 [==============================] - 1486s 911ms/step - loss: 0.1981 - accuracy: 0.9095 - val_loss: 0.9132 - val_accuracy: 0.8406\n",
      "Epoch 6/10\n",
      "1632/1632 [==============================] - 1467s 899ms/step - loss: 0.1968 - accuracy: 0.9116 - val_loss: 1.1303 - val_accuracy: 0.8333\n",
      "Epoch 7/10\n",
      "1632/1632 [==============================] - 1451s 889ms/step - loss: 0.1885 - accuracy: 0.9148 - val_loss: 1.2421 - val_accuracy: 0.8189\n",
      "Epoch 8/10\n",
      "1632/1632 [==============================] - 1424s 872ms/step - loss: 0.1898 - accuracy: 0.9132 - val_loss: 0.6530 - val_accuracy: 0.8562\n",
      "Epoch 9/10\n",
      "1632/1632 [==============================] - 1566s 959ms/step - loss: 0.1804 - accuracy: 0.9155 - val_loss: 0.6954 - val_accuracy: 0.8667\n",
      "Epoch 10/10\n",
      "1632/1632 [==============================] - 1507s 924ms/step - loss: 0.1767 - accuracy: 0.9183 - val_loss: 1.5308 - val_accuracy: 0.8297\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=10  # Adjust this as needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrop_disease_model.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save('crop_disease_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    " import os\n",
    "\n",
    "# Save the model\n",
    "model.save('crop_disease_model.h5')\n",
    "\n",
    "# Check if the file is saved\n",
    "if os.path.exists('crop_disease_model.h5'):\n",
    "    print(\"Model saved successfully!\")\n",
    "else:\n",
    "    print(\"Error: Model not saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
